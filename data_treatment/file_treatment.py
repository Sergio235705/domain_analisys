"""
class to analyse and use a json file generated by certificate_file_generator.py
"""

import json
import csv
import sys
import os

from cert_treatment import CertTreatment
project_root = "/".join(os.path.abspath(__file__).split("/")[:-2])+"/"
sys.path.append(project_root)
from data_collect import safebrowsing_API
from domain_name_analysis import Analyser

class FileTreatment:
    def __init__(self, file_path):
        self.file = open(file_path, 'r')
        self.content = json.load(self.file)
        self.keys = list(self.content.keys())
        self.nb_cert = len(self.keys)

    def get_nb_certificates(self):
        return self.nb_cert

    def write_in_csv(self, file_path, fields, rows):
        """
        write a csvfile at file_path with the content
        in rows and the comumn headers in fields
        """
        csv_file = open(file_path, 'w')
        csvwriter = csv.writer(csv_file)
        csvwriter.writerow(fields)
        csvwriter.writerows(rows)


    def annotate(self, csv_file_path):
        """
        creates a csv file at csv_file_path and fill it with 4 columns:
        the address, the response of googleSafeBrowsingAPI and the 2 parameters given by googleSafeBrowsingAPI
        """

        # file creation
        try:
            f = open(csv_file_path, "x") # raises an error if the file exists
            f.close()
        except:
            os.remove(csv_file_path)
            f = open(csv_file_path, "x")
            f.close()

        sb = safebrowsing_API.SafebrowsingAPI()

        fields = ['domain_name', 'is_suspicious', 'threatType', 'platformType']
        analyser = Analyser("", "")
        # Add a column for each feature (named Featurei)
        for i in range(analyser.number_features):
            fields.append('Feature' + str(i + 1))

        rows = []
        count = 1

        group_count = 0
        group_list = []

        for cert_name in self.keys:
            handler = CertTreatment(self.content[cert_name])
            domain_name = handler.get_domain_name()
            authority_name = handler.get_authority()
            group_list.append(domain_name)
            group_count += 1

            if group_count == 200 or count == self.nb_cert:
                # every 100 certificates or if it's at the end of the file, we make a 
                # request to the safebrowsing_API and store its results in the list "rows" 
                # to put it at the end on the csv file
                result = sb.multiple_requests(group_list)
                result_dict = eval(result)

                group_matches = {}
                if len(result_dict.keys()) != 0:
                    # if the request gave results, I parse them
                    if "error" in result_dict:
                        # too much api requests for the day
                        self.write_in_csv(csv_file_path, fields, rows)
                        print("\n\nERROR WITH THE API")
                        print ("There is " + str(count - group_count) + " on " + str(self.nb_cert) + " certificates wanted")
                        print("error: " + result_dict["error"])
                        return 0
                    for elt in result_dict["matches"]:
                        # filling a new dict with the result to have it indexed by the url, so I can search through
                        group_matches[elt["threat"]["url"]] = (elt["threatType"], elt["platformType"])

                for elt in group_list:
                    row_features = self.get_features_values(elt, authority_name) # Features
                    suspicious = False # Is suspicious
                    threatType = ''
                    platformType = ''
                    if elt in group_matches:
                        suspicious = True
                        threatType = group_matches[elt][0]
                        platformType = group_matches[elt][1]
                    row = [elt, suspicious, threatType, platformType]
                    for feature in row_features:
                        row.append(feature)
                    rows.append(row)

                group_count = 0
                group_list = []
                print (str(count) + " certificates analysed")
            count +=1
        self.write_in_csv(csv_file_path, fields, rows)
    
    def get_features_values(self, domain_name, authority):
        """
            Compute value of the features for the domain name and return it in a row
        """
        # Create analyser for the domain name
        analyser = Analyser(domain_name, authority)
        row = []
        row.append(analyser.levenshtein())
        row.append(analyser.issued_from_free_CA())
        row.append(analyser.deeply_nested_subdomains())
        row.append(analyser.suspicious_tld())
        row.append(analyser.inner_tld_in_subdomain())
        row.append(analyser.suspicious_keywords())
        row.append(analyser.hyphens_in_subdomain())
        row.append(analyser.suspicious_domain_length())
        row.append(analyser.suspicious_characters())
        row.append(analyser.suspicious_age_domain())
        row.append(analyser.suspicious_date_creation())
        row.append(analyser.suspicious_date_expiry())
        row.append(analyser.suspicious_valid_period_domain())
        row.append(analyser.suspicious_registrant_name())
        row.append(analyser.suspicious_registrant_organization())
        row.append(analyser.suspicious_registrarURL())
        row.append(analyser.suspicious_parkerURL())
        return row

    def see_horrible(self):
        """
        For test purposes, just display the suspicious domain names in the console
        """
        sb = safebrowsing_API.SafebrowsingAPI()
        good_count = 0
        for cert_name in self.keys:
            handler = CertTreatment(self.content[cert_name])
            domain_name = handler.get_domain_name()
            result = sb.request(domain_name)
            if result == '{}\n':
                good_count += 1
            else:
                print(domain_name, "\n", result)
            if good_count%100 == 0:
                print("There is "+ str(good_count) + " non-suspocious domains so far")
        print("There was no problem with ", good_count, " domains")
